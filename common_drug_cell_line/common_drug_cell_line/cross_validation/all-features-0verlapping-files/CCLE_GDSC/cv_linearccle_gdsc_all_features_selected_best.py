# -*- coding: utf-8 -*-
"""CV_linearCCLE_gCSI_all_features.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S77yBqEdignu8PNBTXmHeQP3_Dd0IxcR
"""

from sklearn.preprocessing import StandardScaler
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


data_path= '/Users/kritibbhattarai/Downloads/trisha-kritib/data/sensitivity_data/CCLE_GDSC_A_B_C_Cprime/'

out_path = '/Users/kritibbhattarai/Downloads/trisha-kritib/code/new_pipeline/common_drug_cell_line/results_kritib/'

# C and C' 

CCLE=pd.read_csv(data_path+'CCLE_C.csv')
GDSC=pd.read_csv(data_path+'GDSC_C_prime.csv')

CCLE.shape, GDSC.shape

CCLE = CCLE.set_index(['cell line', 'compound' ])
GDSC = GDSC.set_index(['cell line', 'compound' ])

ccle_x = CCLE.iloc[:, 0:-1]
ccle_y = CCLE.iloc[:, -1]

gdsc_x = GDSC.iloc[:, 0:-1]
gdsc_y = GDSC.iloc[:, -1]

#last 21 columns are tissue types. one-hot encoding
gdsc_x.iloc[0:2, 0:-21]

gdsc_x.iloc[:, 0:-21] = StandardScaler().fit_transform(gdsc_x.iloc[:, 0:-21])
ccle_x.iloc[:, 0:-21] = StandardScaler().fit_transform(ccle_x.iloc[:, 0:-21])

from sklearn.model_selection import train_test_split

gdsc_X_train, gdsc_X_test, gdsc_y_train, gdsc_y_test = train_test_split(gdsc_x, gdsc_y, test_size = 0.30, random_state = 42) 
ccle_X_train, ccle_X_test, ccle_y_train, ccle_y_test = train_test_split(ccle_x, ccle_y,test_size = 0.30, random_state = 42)


from numpy import mean
from numpy import std
from sklearn.datasets import make_classification
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn import datasets, linear_model
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import plotly.express as px
import plotly.graph_objects as go
from sklearn.ensemble import RandomForestRegressor


"""Selected Best"""

maes_sb_ccle=[]
mses_sb_ccle=[]
r2s_sb_ccle=[]
kf = KFold(n_splits=10, shuffle = True, random_state= 1)


i = 1            
for train_index, test_index in kf.split(ccle_x,ccle_y):
    #model = MLP()

    #fit ccle data to m1
    ccle_x_train= ccle_x.iloc[train_index, :]
    ccle_x_test= ccle_x.iloc[test_index, :]


    ccle_Y_train = ccle_y[train_index]
    ccle_Y_test = ccle_y[test_index]

    m1 = linear_model.Ridge()
    m1.fit(ccle_x_train, ccle_Y_train)


    #fit gdsc data to m2
    gdsc_x_train= gdsc_x.iloc[train_index, :]
    gdsc_x_test= gdsc_x.iloc[test_index, :]


    gdsc_Y_train = gdsc_y[train_index]
    gdsc_Y_test = gdsc_y[test_index]



    #need this for evaluation
    mixed_x_test = pd.concat([ccle_x_test, gdsc_x_test], ignore_index=True)
    mixed_y_test = pd.concat([ccle_Y_test, gdsc_Y_test], ignore_index=True)

    

    # Make predictions using the testing set
    mixed_y_pred = m1.predict(mixed_x_test)


    #test on mixed data 
    print("Results for Fold: ", i)
    print("-----------------------------------------------------------------------")
    i=i+1

    #mean squared loss
    mses_sb_ccle.append(mean_squared_error(mixed_y_test, mixed_y_pred))
    print("Mean squared error: %.2f" % mean_squared_error(mixed_y_test, mixed_y_pred))
    
    #mean absolute error
    maes_sb_ccle.append(mean_absolute_error(mixed_y_test, mixed_y_pred))
    print("Mean absolute error: %.2f" % mean_absolute_error(mixed_y_test, mixed_y_pred))

    # The coefficient of determination: 1 is perfect prediction
    r2s_sb_ccle.append(r2_score(mixed_y_test, mixed_y_pred))
    print("Coefficient of determination: %.2f" % r2_score(mixed_y_test, mixed_y_pred))

    print("-----------------------------------------------------------------------")
#0.02, 0.10, 0.18

maes_sb_gdsc=[]
mses_sb_gdsc=[]
r2s_sb_gdsc=[]
kf = KFold(n_splits=10, shuffle = True, random_state= 1)


i = 1            
for train_index, test_index in kf.split(ccle_x,ccle_y):
    #model = MLP()

    #fit ccle data to m1
    ccle_x_train= ccle_x.iloc[train_index, :]
    ccle_x_test= ccle_x.iloc[test_index, :]


    ccle_Y_train = ccle_y[train_index]
    ccle_Y_test = ccle_y[test_index]



    #fit gdsc data to m2
    gdsc_x_train= gdsc_x.iloc[train_index, :]
    gdsc_x_test= gdsc_x.iloc[test_index, :]


    gdsc_Y_train = gdsc_y[train_index]
    gdsc_Y_test = gdsc_y[test_index]


    m2 = linear_model.Ridge()
    m2.fit(gdsc_x_train, gdsc_Y_train)

    #need this for evaluation
    mixed_x_test = pd.concat([ccle_x_test, gdsc_x_test], ignore_index=True)
    mixed_y_test = pd.concat([ccle_Y_test, gdsc_Y_test], ignore_index=True)

    

    # Make predictions using the testing set
    mixed_y_pred = m2.predict(mixed_x_test)


    #test on mixed data 
    print("Results for Fold: ", i)
    print("-----------------------------------------------------------------------")
    i=i+1

    #mean squared loss
    mses_sb_gdsc.append(mean_squared_error(mixed_y_test, mixed_y_pred))
    print("Mean squared error: %.2f" % mean_squared_error(mixed_y_test, mixed_y_pred))
    
    #mean absolute error
    maes_sb_gdsc.append(mean_absolute_error(mixed_y_test, mixed_y_pred))
    print("Mean absolute error: %.2f" % mean_absolute_error(mixed_y_test, mixed_y_pred))

    # The coefficient of determination: 1 is perfect prediction
    r2s_sb_gdsc.append(r2_score(mixed_y_test, mixed_y_pred))
    print("Coefficient of determination: %.2f" % r2_score(mixed_y_test, mixed_y_pred))

    print("-----------------------------------------------------------------------")


with open("results/selected_best.txt", "a") as output:
    output.write("ccle_gdsc_selected_best_mae="+str(maes_sb_gdsc)+"\n")
    output.write("ccle_gdsc_selected_best_mse="+str(mses_sb_gdsc)+"\n")
    output.write("ccle_gdsc_selected_best_r2="+str(r2s_sb_gdsc)+"\n")
