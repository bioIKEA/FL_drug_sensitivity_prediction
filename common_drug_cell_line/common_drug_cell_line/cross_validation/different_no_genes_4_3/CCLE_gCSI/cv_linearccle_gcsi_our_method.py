# -*- coding: utf-8 -*-
"""CV_linearCCLE_GDSC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17G5ZhI6J2GmB1HF94VyTaU7T4hU3l_aR
"""

from sklearn.preprocessing import StandardScaler
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

data_path= '/Users/kritibbhattarai/Downloads/trisha-kritib/data/kritib-data/'

out_path = '/Users/kritibbhattarai/Downloads/trisha-kritib/code/new_pipeline/common_drug_cell_line/results_kritib/'

# C and C' 
list_of_CCLE_files=['CCLE_paired_common_with_gcsi_50.csv','CCLE_paired_common_with_gcsi_100.csv','CCLE_paired_common_with_gcsi_200.csv','CCLE_paired_common_with_gcsi_500.csv','CCLE_paired_common_with_gcsi_902.csv']
list_of_gCSI_files=['gCSI_paired_common_with_ccle_50.csv','gCSI_paired_common_with_ccle_100.csv','gCSI_paired_common_with_ccle_200.csv','gCSI_paired_common_with_ccle_500.csv','gCSI_paired_common_with_ccle_902.csv']

our_method_mae=[]
our_method_mse=[]
our_method_r2=[]

for counter in range(len(list_of_CCLE_files)):
    CCLE=pd.read_csv(data_path+list_of_CCLE_files[counter], index_col=0)
    gCSI=pd.read_csv(data_path+list_of_gCSI_files[counter], index_col=0)
    CCLE=CCLE.reset_index(drop=True)
    CDSC=gCSI.reset_index(drop=True)

    ccle_x = CCLE.iloc[:, 0:-1]
    ccle_y = CCLE.iloc[:, -1]

    gCSI = gCSI.reset_index()
    gCSI = gCSI.drop(columns='index')

    gcsi_x = gCSI.iloc[:, 0:-1]
    gcsi_y = gCSI.iloc[:, -1]

    gcsi_x.iloc[0:2, 0:-21]

    gcsi_x.iloc[:, 0:-21] = StandardScaler().fit_transform(gcsi_x.iloc[:, 0:-21])
    ccle_x.iloc[:, 0:-21] = StandardScaler().fit_transform(ccle_x.iloc[:, 0:-21])

    from sklearn.model_selection import train_test_split

    gcsi_X_train, gcsi_X_test, gcsi_y_train, gcsi_y_test = train_test_split(gcsi_x, gcsi_y, test_size = 0.30, random_state = 42) 
    ccle_X_train, ccle_X_test, ccle_y_train, ccle_y_test = train_test_split(ccle_x, ccle_y,test_size = 0.30, random_state = 42)

    """Our method cv"""

    from numpy import mean
    from numpy import std
    from sklearn.datasets import make_classification
    from sklearn.model_selection import KFold
    from sklearn.model_selection import cross_val_score
    from sklearn import datasets, linear_model
    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
    import plotly.express as px
    import plotly.graph_objects as go
    from sklearn.ensemble import RandomForestRegressor


    maes_our=[]
    mses_our=[]
    r2s_our=[]
    kf = KFold(n_splits=10, shuffle = True, random_state= 1)


    i = 1            
    for train_index, test_index in kf.split(ccle_x,ccle_y):
        #model = MLP()

        #fit ccle data to m1
        ccle_x_train= ccle_x.iloc[train_index, :]
        ccle_x_test= ccle_x.iloc[test_index, :]


        ccle_Y_train = ccle_y[train_index]
        ccle_Y_test = ccle_y[test_index]

        m1 = linear_model.Ridge()
        m1.fit(ccle_x_train, ccle_Y_train)

        # Make predictions using the testing set
        ccle_y_pred = m1.predict(ccle_x_test)

        #fit gcsi data to m2
        gcsi_x_train= gcsi_x.iloc[train_index, :]
        gcsi_x_test= gcsi_x.iloc[test_index, :]


        gcsi_Y_train = gcsi_y[train_index]
        gcsi_Y_test = gcsi_y[test_index]

        m2=  linear_model.Ridge()
        m2.fit(gcsi_x_train, gcsi_Y_train)

        # Make predictions using the testing set
        gcsi_y_pred = m2.predict(gcsi_x_test)


        #need this for evaluation
        mixed_x_test = pd.concat([ccle_x_test, gcsi_x_test], ignore_index=True)
        mixed_y_test = pd.concat([ccle_Y_test, gcsi_Y_test], ignore_index=True)

        #predictions on training sets. m1 to predict CCLE and m2 to predict gCSI
        ccle_y_train_pred = m1.predict(ccle_x_train)
        gcsi_y_train_pred = m2.predict(gcsi_x_train)

        m4 = linear_model.LinearRegression()
        #for m4, gcsi is the x and ccle is the y, reverse for m3
        m4.fit(gcsi_y_train_pred.reshape(-1, 1), ccle_y_train_pred.reshape(-1,1))

        # Make predictions using the testing set
        ccle_y_pred_m4 = m4.predict(gcsi_y_pred.reshape(-1,1))

        #avg ccle values predicted by m4 + gcsi input y values  to m4 
        gcsi = (ccle_y_pred_m4 + gcsi_y_pred.reshape(-1,1))/2


        m3 =linear_model.LinearRegression()
        #for m3, gcsi is the y and ccle is the x, reverse for m4
        m3.fit(ccle_y_train_pred.reshape(-1, 1), gcsi_y_train_pred.reshape(-1,1))

        # Make predictions using the testing set
        gcsi_y_pred_m3 = m3.predict(ccle_y_pred.reshape(-1,1))

        ccle = (gcsi_y_pred_m3 + ccle_y_pred.reshape(-1,1))/2


        #use squeeze to make it one dimensional
        ccle = pd.Series(ccle.squeeze())
        gcsi =pd.Series(gcsi.squeeze())

        #concat for comparing with mixed_y_test
        concated = pd.concat([ccle, gcsi], ignore_index=True)

        #test on mixed data 
        print("Results for Fold: ", i)
        print("-----------------------------------------------------------------------")
        i=i+1

        #mean squared loss
        mses_our.append(mean_squared_error(mixed_y_test, concated))
        print("Mean squared error: %.2f" % mean_squared_error(mixed_y_test, concated))
        
        #mean absolute error
        maes_our.append(mean_absolute_error(mixed_y_test, concated))
        print("Mean absolute error: %.2f" % mean_absolute_error(mixed_y_test, concated))

        # The coefficient of determination: 1 is perfect prediction
        r2s_our.append(r2_score(mixed_y_test, concated))
        print("Coefficient of determination: %.2f" % r2_score(mixed_y_test, concated))

        print("-----------------------------------------------------------------------")
    our_method_mae.append(maes_our)
    our_method_mse.append(mses_our)
    our_method_r2.append(r2s_our)
with open("results/our_method.txt", "a") as output:
    # output.write(our_method_mae)
    # output.write(our_method_mse)
    # output.write(our_method_r2)
    output.write("our_method_mae="+str(our_method_mae)+"\n")
    output.write("our_method_mse="+str(our_method_mse)+"\n")
    output.write("our_method_r2="+str(our_method_r2)+"\n")

'''

"""Plots"""

plt.boxplot([ maes_our, maes_cd,  maes_sb_gcsi, maes_wa, maes_ma])
plt.title("Mean Absolute Error")
plt.xticks([1, 2, 3, 4, 5], ['Our method', 'Combining datasets', 'Selecting best', 'Result averaging', 'Model averaging'])
plt.xticks(rotation = 90)
plt.savefig(out_path+'mean_absolute_error_boxplots_cv.png', dpi=300, bbox_inches= 'tight')
plt.show()

plt.boxplot([mses_our, mses_cd,  mses_sb_gcsi, mses_wa, mses_ma])
plt.title("Mean Squared Error")
plt.xticks([1, 2, 3, 4, 5], ['Our method', 'Combining datasets', 'Selecting best', 'Result averaging', 'Model averaging'])
plt.xticks(rotation = 90)
plt.savefig(out_path+'mean_squared_error_boxplots_cv.png', dpi=300, bbox_inches= 'tight')
plt.show()

plt.boxplot([r2s_our, r2s_cd,  r2s_sb_gcsi, r2s_wa, r2s_ma])
plt.title("Coefficient of determination")
plt.xticks([1, 2, 3, 4, 5], ['Our method', 'Combining datasets', 'Selecting best', 'Result averaging', 'Model averaging'])
plt.xticks(rotation = 90)
plt.savefig(out_path+'r2_boxplots_cv.png', dpi=300, bbox_inches= 'tight')
plt.show()

"""For SB, ccle is worse. So, we keep gcsi."""


'''
